# 机器学习

​	从广义上来说，机器学习是一种能够赋予机器学习的能力以此让它完成直接编程无法完成的功能的方法。但从实践的意义上来说，机器学习是一种通过利用数据，训练出模型，然后使用模型预测的一种方法。
​	“训练”与“预测”是机器学习的两个过程，“模型”则是过程的中间输出结果，“训练”产生“模型”，“模型”指导 “预测”。机器学习方法是计算机利用已有的数据(经验)，得出了某种模型(规律)，并利用此模型预测未来的一种方法。

1. 数据采集：获取需要的数据

2. 数据处理：清洗数据，处理缺失值、异常值、数据编码和重复数据，确保数据的质量和一致性

3. 特征工程：特征工程是将原始数据转换为能被算法理解和利用的形式，是机器学习中最耗时也是最重要的一环
   - 特征提取：结合任务自身特点，通过结合和转换原始特征集，构造出新的特征
   - 特征选择：从大规模的特征空间中提取与任务相关的特征
     1. Filter过滤法：按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征
        - 方差过滤：通过特征本身的方差来筛选特征，一个特征的方差越小，表明，该特征的变化越不明显，变化越不明显的特征对我们区分标签没有太大的作用所以应该消除这些特征
        - 相关性过滤：去除高度相关的特征，因为如果两个特征高度相关，那么它们提供的信息是冗余的，保留一个即可
          1. 卡方过滤
          2. F检验
          3. 互信息法
     2. Wrapper包装法：根据目标函数（通常是预测效果评分），每次选择若干特征，或者排除若干特征
     3. Embedded嵌入法：先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征
   - 数据标准化/归一化
   - 特征矩阵

4. 选择模型：根据问题性质（分类、回归、聚类等）选择合适的机器学习模型，基于一个问题类型和数据特性，选择一个或多个算法进行试验
   1. 监督学习：监督学习是指使用带标签的数据进行训练，模型通过学习输入数据与标签之间的关系，来做出预测或分类

      - 分类：对各种事物进行分类，用于离散预测

      - 回归：预测连续的、具体的数值

        ![](E:\Notes\笔记图片\机器学习—监督学习.png)

   2. 无监督学习：非监督学习是指在机器学习过程中，用来训练机器的数据是没有标签的，机器只能依靠自己不断探索，对知识进行归纳和总结，尝试发现数据中的内在规律和特征，从而对训练数据打标签

      - 聚类：将观察值聚成一个一个的组，每个组都含有一个或几个特征。聚类的目的是将相似的东西聚在一起，而并不关心这类东西具体是什么

        - 获取最优K值：手肘法、轮廓系数法

      - 降维：减少一个数据集的变量数量，同时保证传达信息的准确性

      - 关联：发现事物共现的概率

        ![](E:\Notes\笔记图片\机器学习—无监督学习.png)

   3. 半监督学习：利用大量无标签样本来辅助少量有标签样本的学习。机器学习中的监督学习通过对大量有标签的样本进行学习，建立模型预测未知样本。然而，现实世界中有大量的无标签样本和少量的有标签样本。如果只用少量的有标签样本训练机器，学习系统往往很难具备强泛化能力，同时大量的无标签样本得不到利用，也会对数据资源造成极大的浪费。如何在少量的有标签样本下，利用大量的无标签样本改善机器学习性能，成为机器学习研究者关注的问题之一。

   4. 自监督学习

5. 评估模型：使用测试集来评估模型的性能，常用的指标包括准确率、召回率、F1分数等

6. 模型优化

7. 部署模型

8. 反馈循环

   

